"""
å›¾ç‰‡å¤„ç†æœåŠ¡æ¨¡å—
åŒ…å«OCRã€ç¿»è¯‘ã€å›¾åƒä¿®å¤ç­‰åŠŸèƒ½
"""
import os
# å¿…é¡»åœ¨ import paddle ä¹‹å‰è®¾ç½®ï¼Œé¿å… OneDNN/PIR å…¼å®¹æ€§å¯¼è‡´çš„ NotImplementedError
os.environ["FLAGS_use_mkldnn"] = "0"
os.environ["FLAGS_use_new_executor"] = "0"

import json
import numpy as np
from paddleocr import PaddleOCR
import cv2
from PIL import Image, ImageDraw, ImageFont
import re
import time
from openai import OpenAI
from typing import List, Dict, Any, Optional

from app.core.config import settings

try:
    from simple_lama_inpainting import SimpleLama
    LAMA_AVAILABLE = True
except ImportError:
    LAMA_AVAILABLE = False
    print("âš ï¸ simple_lama_inpainting æœªå®‰è£…ï¼Œå°†ä½¿ç”¨OpenCVä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")

# -----------------------------
# è¾“å…¥è½¬å›¾ç‰‡åˆ—è¡¨
# -----------------------------

def convert_input_to_images(input_path: str, output_dir: str = None) -> List[str]:
    """
    ğŸ“‚ è¾“å…¥å¤„ç†å™¨ï¼šä»…æ”¯æŒå›¾ç‰‡ï¼Œç›´æ¥è¿”å›è·¯å¾„åˆ—è¡¨ï¼›å…¶ä»–æ ¼å¼è¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    file_ext = os.path.splitext(input_path)[1].lower()
    if file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']:
        return [input_path]
    print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒå›¾ç‰‡: .jpg, .jpeg, .png, .bmp, .tif, .tiff")
    return []


# -----------------------------
# è‡ªåŠ¨çŸ«æ­£
# -----------------------------

def order_points(pts):
    """å¯¹å››ä¸ªè§’ç‚¹è¿›è¡Œæ’åºï¼šå·¦ä¸Šï¼Œå³ä¸Šï¼Œå³ä¸‹ï¼Œå·¦ä¸‹"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # å·¦ä¸Š
    rect[2] = pts[np.argmax(s)]  # å³ä¸‹
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # å³ä¸Š
    rect[3] = pts[np.argmax(diff)]  # å·¦ä¸‹
    return rect


def auto_correct_perspective(img_path: str) -> str:
    """
    ğŸ“ è‡ªåŠ¨é€è§†çŸ«æ­£ï¼šæŠŠæ­ªæ–œçš„èº«ä»½è¯æ‹‰æ­£
    """
    img = cv2.imread(img_path)
    if img is None:
        return img_path

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edged = cv2.Canny(blurred, 75, 200)

    cnts, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        print("âš ï¸ æœªæ£€æµ‹åˆ°è½®å»“ï¼Œè·³è¿‡çŸ«æ­£")
        return img_path

    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]

    screenCnt = None
    for c in cnts:
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)

        if len(approx) == 4 and cv2.contourArea(c) > 50000:
            screenCnt = approx
            break

    if screenCnt is None:
        print("âš ï¸ æœªæ‰¾åˆ°çŸ©å½¢å¡è¯åŒºåŸŸï¼Œè·³è¿‡çŸ«æ­£")
        return img_path

    print("ğŸ“ æ£€æµ‹åˆ°å€¾æ–œå¡è¯ï¼Œæ­£åœ¨è¿›è¡Œé€è§†å˜æ¢çŸ«æ­£...")

    pts = screenCnt.reshape(4, 2)
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]], dtype="float32")

    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))

    name, ext = os.path.splitext(img_path)
    new_path = f"{name}_corrected{ext}"
    cv2.imwrite(new_path, warped)

    print(f"âœ… çŸ«æ­£å®Œæˆ: {new_path}")
    return new_path


def preprocess_resize_image(input_path: str, target_width: int = None) -> str:
    """
    ğŸ–¼ï¸ å›¾åƒé¢„å¤„ç†ï¼šå°†å›¾ç‰‡ç­‰æ¯”ä¾‹ç¼©æ”¾è‡³æŒ‡å®šå®½åº¦
    """
    if target_width is None:
        target_width = settings.TARGET_IMAGE_WIDTH

    if not os.path.exists(input_path):
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return input_path

    img = cv2.imread(input_path)
    if img is None:
        print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {input_path}")
        return input_path

    h, w = img.shape[:2]

    if abs(w - target_width) < 5:
        print(f"ğŸ“ å›¾ç‰‡å®½åº¦ ({w}px) å·²ç¬¦åˆæ ‡å‡†ï¼Œè·³è¿‡ç¼©æ”¾ã€‚")
        return input_path

    scale = target_width / w
    new_h = int(h * scale)

    print(f"ğŸ”„æ­£åœ¨é¢„å¤„ç†ç¼©æ”¾: {w}x{h} â†’ {target_width}x{new_h} (ç¼©æ”¾æ¯”: {scale:.2f})")

    interpolation = cv2.INTER_AREA if scale < 1 else cv2.INTER_LINEAR
    resized_img = cv2.resize(img, (target_width, new_h), interpolation=interpolation)

    dir_name = os.path.dirname(input_path)
    file_name = os.path.basename(input_path)
    name, ext = os.path.splitext(file_name)

    new_filename = f"{name}_1080p{ext}"
    new_path = os.path.join(dir_name, new_filename)

    cv2.imwrite(new_path, resized_img)
    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œä½¿ç”¨æ–°å›¾ç‰‡: {new_path}")

    return new_path


# -----------------------------
# DeepSeek é…ç½®
# -----------------------------
deepseek_client = OpenAI(
    api_key=settings.DEEPSEEK_API_KEY,
    base_url=settings.DEEPSEEK_BASE_URL
)

# -----------------------------
# åˆå§‹åŒ– OCR
# -----------------------------
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=True,
    lang="ch"
)

# åˆå§‹åŒ– LaMa æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
lama_model = None
if LAMA_AVAILABLE:
    try:
        print("ğŸ¤– æ­£åœ¨åŠ è½½ AI æ¶ˆé™¤æ¨¡å‹ (LaMa)...")
        lama_model = SimpleLama()
    except Exception as e:
        print(f"âš ï¸ LaMa æ¨¡å‹åŠ è½½å¤±è´¥: {e}")


# -----------------------------
# é€šç”¨æå–å‡½æ•°
# -----------------------------
def extract_all_items(result):
    items = []

    for elem in result:
        if isinstance(elem, dict):
            res = elem.get("res", elem)
            texts = res.get("rec_texts") or res.get("texts") or []
            scores = res.get("rec_scores") or []
            polys = res.get("rec_polys") or res.get("rec_boxes") or []

            for t, s, p in zip(texts, scores, polys):
                if isinstance(p, np.ndarray):
                    p = p.tolist()
                items.append({
                    "text": t,
                    "score": float(s) if s is not None else None,
                    "box": p
                })

        elif hasattr(elem, "texts") and hasattr(elem, "boxes"):
            texts = elem.texts
            boxes = elem.boxes
            scores = getattr(elem, "scores", [None] * len(texts))

            for t, s, b in zip(texts, scores, boxes):
                try:
                    box_list = b.tolist()
                except:
                    box_list = b
                items.append({
                    "text": t,
                    "score": float(s) if s is not None else None,
                    "box": box_list
                })

        elif isinstance(elem, (list, tuple)):
            for row in elem:
                if isinstance(row, (list, tuple)) and len(row) >= 2:
                    box = row[0]
                    pair = row[1]
                    if isinstance(pair, (list, tuple)) and len(pair) >= 2:
                        text = pair[0]
                        score = float(pair[1])
                    else:
                        text = pair
                        score = None

                    try:
                        box_list = [list(map(int, p)) for p in box]
                    except:
                        box_list = box

                    items.append({
                        "text": text,
                        "score": score,
                        "box": box_list
                    })

    return items


# -----------------------------
# æ™ºèƒ½åˆ†å‰²
# -----------------------------
def split_merged_items(items):
    result = []
    split_keywords = ["å§“å", "æ€§åˆ«", "æ°‘æ—", "å…¬æ°‘èº«ä»½å·ç "]
    protect_keywords = ["å‡ºç”Ÿ", "ä½å€", "åœ°å€"]

    for item in items:
        text = item["text"]
        box = item["box"]
        score = item["score"]

        is_protected = any(kw in text for kw in protect_keywords)
        has_date = re.search(r'\d{4}.*?å¹´.*?\d+.*?æœˆ.*?\d+.*?æ—¥', text)
        has_id = re.search(r'\d{15,18}', text)
        has_address = any(kw in text for kw in ['çœ', 'å¸‚', 'åŒº', 'å¿', 'è¡—', 'è·¯', 'å·', 'å®¤', 'æˆ¿'])

        if is_protected or has_date or has_id or has_address:
            result.append(item)
            continue

        needs_split = False

        if " " in text or "ã€€" in text:
            found_keywords = sum(1 for kw in split_keywords if kw in text)
            if found_keywords >= 2:
                needs_split = True

        if needs_split:
            parts = split_text_by_rules(text, split_keywords)

            if len(parts) > 1:
                sub_items = calculate_sub_boxes(parts, box, score)
                result.extend(sub_items)
                print(f"ğŸ”§ åˆ†å‰²: '{text}' â†’ {parts}")
                continue

        result.append(item)

    return result


def split_text_by_rules(text, keywords):
    parts = []

    if " " in text or "ã€€" in text:
        parts = re.split(r'[\sã€€]+', text)
        parts = [p.strip() for p in parts if p.strip()]

        if len(parts) > 1:
            return parts

    temp_parts = []
    remaining = text

    while remaining:
        matched = False

        for kw in sorted(keywords, key=len, reverse=True):
            if remaining.startswith(kw):
                temp_parts.append(kw)
                remaining = remaining[len(kw):]
                matched = True
                break

        if not matched:
            if temp_parts:
                next_kw_pos = len(remaining)
                for kw in keywords:
                    pos = remaining.find(kw)
                    if pos > 0:
                        next_kw_pos = min(next_kw_pos, pos)

                value = remaining[:next_kw_pos]
                if value:
                    temp_parts.append(value)
                    remaining = remaining[next_kw_pos:]
            else:
                first_kw_pos = len(remaining)
                for kw in keywords:
                    pos = remaining.find(kw)
                    if pos >= 0:
                        first_kw_pos = min(first_kw_pos, pos)

                if first_kw_pos < len(remaining):
                    temp_parts.append(remaining[:first_kw_pos])
                    remaining = remaining[first_kw_pos:]
                else:
                    temp_parts.append(remaining)
                    remaining = ""

    if len(temp_parts) > 1:
        return temp_parts

    return [text]


def calculate_sub_boxes(parts, original_box, score):
    sub_items = []

    x1, y1 = original_box[0]
    x2, y2 = original_box[1]
    x3, y3 = original_box[2] if len(original_box) > 2 else original_box[1]
    x4, y4 = original_box[3] if len(original_box) > 3 else original_box[0]

    total_width = x2 - x1
    total_chars = sum(len(p) for p in parts) + (len(parts) - 1)

    if total_chars == 0:
        return [{"text": "".join(parts), "score": score, "box": original_box}]

    char_width = total_width / total_chars
    current_x = x1

    for i, part in enumerate(parts):
        if not part:
            continue

        part_width = len(part) * char_width

        new_box = [
            [int(current_x), int(y1)],
            [int(current_x + part_width), int(y2)],
            [int(current_x + part_width), int(y3)],
            [int(current_x), int(y4)]
        ]

        sub_items.append({
            "text": part,
            "score": score,
            "box": new_box
        })

        current_x += part_width + char_width

    return sub_items


# -----------------------------
# æ™ºèƒ½åˆå¹¶åœ°å€è¡Œ
# -----------------------------
def get_global_metrics(items):
    """è®¡ç®—å…¨å›¾çš„æ ‡å‡†è¡Œé«˜å’Œæ ‡å‡†å­—ç¬¦å®½åº¦"""
    heights = []
    char_widths = []

    for item in items:
        box = item['box']
        text = item['text']
        if not text:
            continue

        h = abs(box[2][1] - box[0][1])
        heights.append(h)

        w = abs(box[1][0] - box[0][0])
        if len(text) > 0:
            char_widths.append(w / len(text))

    std_h = np.median(heights) if heights else 20
    std_w = np.median(char_widths) if char_widths else 20

    return std_h, std_w


def merge_address_lines(items):
    """åŠ¨æ€é˜ˆå€¼ç‰ˆï¼šæ™ºèƒ½åˆå¹¶åœ°å€è¡Œ"""
    std_h, std_w = get_global_metrics(items)
    print(f"ğŸ“ å›¾ç‰‡æ’ç‰ˆåŸºå‡†: æ ‡å‡†è¡Œé«˜={std_h:.1f}px, æ ‡å‡†å­—å®½={std_w:.1f}px")

    merged_items = []
    i = 0
    n = len(items)

    while i < n:
        current_item = items[i]
        current_text = current_item['text']

        if 'ä½å€' in current_text or 'åœ°å€' in current_text:
            lines_to_merge = [current_item]
            j = i + 1
            merge_count = 0

            current_box = current_item['box']
            current_y_top = current_box[0][1]
            current_y_bottom = current_box[2][1]
            current_x_left = current_box[0][0]

            while j < n and merge_count < 3:
                next_item = items[j]
                next_text = next_item['text']
                next_box = next_item['box']

                next_y_top = next_box[0][1]
                next_x_left = next_box[0][0]

                gap = next_y_top - current_y_bottom

                if gap > 1.5 * std_h:
                    print(f"   âŒ å‚ç›´é—´è·è¿‡å¤§ ({gap:.1f}px > 1.5xæ ‡å‡†é«˜): åœæ­¢åˆå¹¶ '{next_text}'")
                    break

                indent = abs(next_x_left - current_x_left)

                if indent > 4.0 * std_w:
                    print(f"   âŒ æ°´å¹³ç¼©è¿›è¿‡å¤§ ({indent:.1f}px > 4xå­—å®½): åœæ­¢åˆå¹¶ '{next_text}'")
                    break

                if len(next_text) > 40:
                    print(f"   âŒ æ–‡æœ¬è¿‡é•¿: ä¸åˆå¹¶ '{next_text}'")
                    break

                if re.search(r'\d{14,18}', next_text):
                    print(f"   âŒ å‘ç°èº«ä»½è¯å·: åœæ­¢åˆå¹¶ '{next_text}'")
                    break

                if any(kw in next_text for kw in ['å…¬æ°‘èº«ä»½', 'èº«ä»½è¯', 'ç­¾å‘æœºå…³', 'æœ‰æ•ˆæœŸé™']):
                    print(f"   âŒ å‘ç°æ–°å­—æ®µ: åœæ­¢åˆå¹¶ '{next_text}'")
                    break

                lines_to_merge.append(next_item)
                current_y_bottom = next_box[2][1]
                merge_count += 1
                j += 1

            if len(lines_to_merge) > 1:
                merged_text = ''.join([item['text'] for item in lines_to_merge])
                merged_box = merge_boxes_multi(lines_to_merge)
                valid_scores = [item['score'] for item in lines_to_merge if item.get('score')]
                merged_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0

                merged_items.append({
                    'text': merged_text,
                    'score': merged_score,
                    'box': merged_box
                })

                debug_msg = ' + '.join([f"'{item['text']}'" for item in lines_to_merge])
                print(f"ğŸ”— æˆåŠŸåˆå¹¶åœ°å€: {debug_msg} â†’ '{merged_text}'")

                i = j
            else:
                merged_items.append(current_item)
                i += 1
        else:
            merged_items.append(current_item)
            i += 1

    return merged_items


def merge_boxes_multi(items):
    """åˆå¹¶å¤šä¸ªboxï¼Œè¿”å›å¤–æ¥çŸ©å½¢"""
    all_points = []
    for item in items:
        all_points.extend(item['box'])

    xs = [p[0] for p in all_points]
    ys = [p[1] for p in all_points]

    x_min, x_max = min(xs), max(xs)
    y_min, y_max = min(ys), max(ys)

    return [
        [x_min, y_min],
        [x_max, y_min],
        [x_max, y_max],
        [x_min, y_max]
    ]


# -----------------------------
# DeepSeek ç¿»è¯‘
# -----------------------------
FIELD_TRANSLATIONS = {
    'å§“å': 'Name:',
    'æ€§åˆ«': 'Gender:',
    'æ°‘æ—': 'Ethnicity:',
    'å‡ºç”Ÿ': 'Date of Birth:',
    'ä½å€': 'Address:',
    'å…¬æ°‘èº«ä»½å·ç ': 'ID Number:'
}

SINGLE_VALUE_MAP = {
    'ç”·': 'Male',
    'å¥³': 'Female',
    'æ±‰': 'Han'
}

FIELD_KEYS = list(FIELD_TRANSLATIONS.keys())

# -----------------------------
# èº«ä»½è¯èƒŒé¢ï¼ˆå›½å¾½é¢ï¼‰å›ºå®šç¿»è¯‘æ˜ å°„
# -----------------------------
BACKSIDE_FIXED_MAP = {
    'ä¸­åäººæ°‘å…±å’Œå›½': "People's Republic of China",
    'å±…æ°‘èº«ä»½è¯': 'Resident Identity Card',
    'ç­¾å‘æœºå…³': 'Issuing Authority',
    'æœ‰æ•ˆæœŸé™': 'Validity Period',
}

# èƒŒé¢ã€Œç­¾å‘æœºå…³ã€box å³è¾¹ç•Œæ‰©å±•åƒç´ ï¼Œä½¿ "Issuing Authority" èƒ½å•è¡Œæ”¾ä¸‹ï¼ˆOCR åŸ box å¤ªçª„ï¼‰
BACKSIDE_ISSUING_AUTHORITY_BOX_EXTRA_WIDTH = 1000


def _expand_box_right(box, extra_width):
    """å°†å››è¾¹å½¢ box çš„å³è¾¹ç•Œå‘å³æ‰©å±• extra_width åƒç´ ã€‚box: [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]"""
    if not box or len(box) < 4:
        return box
    # æ·±æ‹·è´ï¼Œé¿å…æ”¹åˆ°åŸå§‹æ•°æ®
    new_box = [[float(p[0]), float(p[1])] for p in box]
    # å³ä¸Š [1]ã€å³ä¸‹ [2] çš„ x å¢åŠ 
    new_box[1][0] += extra_width
    new_box[2][0] += extra_width
    return new_box


def translate_all_items_backside(items, from_lang='zh', to_lang='en'):
    """
    èº«ä»½è¯èƒŒé¢ä¸“ç”¨ç¿»è¯‘ï¼šå›ºå®šæ ‡ç­¾ç”¨ç¡¬ç¼–ç æ˜ å°„ï¼Œå˜é‡å€¼ï¼ˆæœºå…³åã€æ—¥æœŸï¼‰èµ° DeepSeekã€‚
    """
    translated_items = []

    for i, item in enumerate(items):
        text = item.get('text', '').strip()
        print(f"[{i + 1}/{len(items)}] ", end="")

        # 1. å›ºå®šæ˜ å°„å‘½ä¸­ â†’ ç›´æ¥ä½¿ç”¨
        if text in BACKSIDE_FIXED_MAP:
            mapped = BACKSIDE_FIXED_MAP[text]
            print(f"âœ… èƒŒé¢å›ºå®šæ˜ å°„: {text} â†’ {mapped}")
            box = item.get("box")
            # ã€Œç­¾å‘æœºå…³ã€è‹±æ–‡ "Issuing Authority" æ¯”ä¸­æ–‡å®½ï¼Œç›´æ¥æ‹‰å®½ box é¿å…æ¢è¡Œ
            if text == 'ç­¾å‘æœºå…³' and box and len(box) >= 4:
                box = _expand_box_right(box, BACKSIDE_ISSUING_AUTHORITY_BOX_EXTRA_WIDTH)
                print(f"   â†’ ç­¾å‘æœºå…³ box å³æ‰© {BACKSIDE_ISSUING_AUTHORITY_BOX_EXTRA_WIDTH}px")
            translated_items.append({
                "text": mapped,
                "original_text": text,
                "score": item.get("score"),
                "box": box,
                "fixed": True  # æ ‡è®°ä¸ºå›ºå®šæ˜ å°„
            })
            continue

        # 2. æ—¥æœŸæ ¼å¼ï¼ˆçº¯æ•°å­—+ç‚¹+æ¨ªçº¿ï¼‰â†’ ä¿æŒåŸæ–‡
        if re.match(r'^[\d.\-/]+$', text):
            print(f"âœ… æ—¥æœŸä¿æŒåŸæ–‡: {text}")
            translated_items.append({
                "text": text,
                "original_text": text,
                "score": item.get("score"),
                "box": item.get("box")
            })
            continue

        # 3. å…¶ä½™ï¼ˆå¦‚ç­¾å‘æœºå…³çš„å…·ä½“åç§°ï¼‰â†’ è°ƒ DeepSeek ç¿»è¯‘
        try:
            translated = translate_basic(text, from_lang, to_lang)
            print(f"âœ… ç¿»è¯‘: {text} â†’ {translated}")
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å‡ºé”™: {e}")
            translated = text

        translated_items.append({
            "text": translated,
            "original_text": text,
            "score": item.get("score"),
            "box": item.get("box")
        })
        time.sleep(0.3)

    return translated_items


def preprocess_field_item_inline(text):
    """å¦‚æœæ–‡æœ¬ä»¥å­—æ®µå¼€å¤´ï¼Œæ‹†åˆ†å¹¶è¿”å› (field_key, value)"""
    for key in sorted(FIELD_KEYS, key=len, reverse=True):
        if text.startswith(key):
            value = text[len(key):].strip()
            return key, value
    return None, text


def translate_basic(text, from_lang='zh', to_lang='en', max_tokens=100):
    """ä»…ç¿»è¯‘å€¼æ–‡æœ¬ï¼ˆvalueï¼‰ï¼Œä¸æ”¹å˜æ•°å­—ï¼Œä¿ç•™ç®€å•map"""
    if not text or not text.strip():
        return text

    if re.match(r'^[\d\s\-X]+$', text):
        return text

    if text in SINGLE_VALUE_MAP:
        return SINGLE_VALUE_MAP[text]

    try:
        lang_map = {
            'zh': 'Chinese',
            'en': 'English',
            'ja': 'Japanese',
            'ko': 'Korean'
        }
        source_lang = lang_map.get(from_lang, 'Chinese')
        target_lang = lang_map.get(to_lang, 'English')

        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {
                    "role": "system",
                    "content": f"You are a professional translator. Translate from {source_lang} to {target_lang}. "
                               f"Rules:\n"
                               f"1. Keep ALL numbers unchanged\n"
                               f"2. Only return the translated text without explanation\n"
                               f"3. For names, use proper capitalization\n"
                               f"4. Be concise and accurate"
                },
                {
                    "role": "user",
                    "content": f"Translate: {text}"
                }
            ],
            temperature=0.2,
            max_tokens=max_tokens
        )

        translated = response.choices[0].message.content.strip().strip('"\'')
        return translated
    except Exception as e:
        print(f"âŒ translate_basic å‡ºé”™: {e}")
        return text


def translate_text_deepseek(text, from_lang='zh', to_lang='en'):
    """å¯¹å•ä¸ª OCR æ–‡æœ¬çš„ç¿»è¯‘"""
    if not text or not text.strip():
        return text

    if re.match(r'^[\d\s\-X]+$', text):
        return text

    sorted_keys = sorted(FIELD_KEYS, key=len, reverse=True)
    pattern = f"({'|'.join(sorted_keys)})"
    parts = re.split(pattern, text)

    valid_parts = [p for p in parts if p.strip()]
    contained_keys = [p for p in valid_parts if p in FIELD_KEYS]

    if len(contained_keys) >= 1:
        translated_parts = []

        for idx, part in enumerate(parts):
            part = part.strip()
            if not part:
                continue

            if part in FIELD_KEYS:
                field_en = FIELD_TRANSLATIONS.get(part, part + ":")
                translated_parts.append(field_en)
            else:
                val_en = translate_basic(part, from_lang, to_lang)
                translated_parts.append(val_en)

        result = " ".join(translated_parts)

        if len(translated_parts) > 1:
            print(f"âœ… å¤šå­—æ®µå†…è”ç¿»è¯‘: {text} â†’ {result}")
            return result

    if text in SINGLE_VALUE_MAP:
        return SINGLE_VALUE_MAP[text]

    try:
        translated = translate_basic(text, from_lang, to_lang)
        print(f"âœ… ç¿»è¯‘: {text} â†’ {translated}")
        return translated
    except Exception as e:
        print(f"âŒ ç¿»è¯‘å‡ºé”™: {e}")
        return text


def translate_all_items(items, from_lang='zh', to_lang='en'):
    """éå† itemsï¼Œå¤„ç†å­—æ®µ+å€¼åˆå¹¶å’Œç¿»è¯‘"""
    translated_items = []
    i = 0
    n = len(items)

    while i < n:
        item = items[i]
        text = item.get('text', '').strip()
        print(f"[{i + 1}/{n}] ", end="")

        field_key, inline_value = preprocess_field_item_inline(text)
        if field_key and inline_value:
            translated_text = translate_text_deepseek(text, from_lang, to_lang)
            translated_items.append({
                "text": translated_text,
                "original_text": text,
                "score": item.get("score"),
                "box": item.get("box")
            })
            i += 1
            time.sleep(0.3)
            continue

        if text in FIELD_KEYS:
            next_idx = i + 1
            if next_idx < n:
                next_text = items[next_idx].get('text', '').strip()
                next_field_key, _ = preprocess_field_item_inline(next_text)
                if next_text and (next_text not in FIELD_KEYS) and not next_field_key:
                    value_en = translate_basic(next_text, from_lang, to_lang)
                    field_en = FIELD_TRANSLATIONS.get(text, text + ":")
                    combined = f"{field_en} {value_en}"
                    print(f"âœ… åˆå¹¶å­—æ®µ+ä¸‹ä¸€è¡Œå€¼: '{text}' + '{next_text}' â†’ {combined}")

                    merged_box = merge_boxes_multi([item, items[next_idx]])
                    avg_score = None
                    try:
                        scores = [s for s in [item.get('score'), items[next_idx].get('score')] if s]
                        avg_score = sum(scores) / len(scores) if scores else None
                    except:
                        avg_score = item.get('score')

                    translated_items.append({
                        "text": combined,
                        "original_text": text + " " + next_text,
                        "score": avg_score,
                        "box": merged_box
                    })
                    i += 2
                    time.sleep(0.3)
                    continue

        translated_text = translate_text_deepseek(text, from_lang, to_lang)
        translated_items.append({
            "text": translated_text,
            "original_text": text,
            "score": item.get("score"),
            "box": item.get("box")
        })

        i += 1
        time.sleep(0.3)

    return translated_items


# -----------------------------
# æ™ºèƒ½æ¶‚æŠ¹
# -----------------------------
def smart_inpaint(img, items):
    """ä½¿ç”¨ AI (LaMa) æ™ºèƒ½æ¶ˆé™¤æ–‡å­—ï¼Œä¿ç•™èƒŒæ™¯åº•çº¹"""
    print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆé®ç½©å¹¶è¿›è¡Œ AI ä¿®å¤...")

    mask = np.zeros(img.shape[:2], dtype=np.uint8)

    for item in items:
        box = item.get("box")
        if not box or len(box) < 4:
            continue

        pts = np.array(box, np.int32)
        center = pts.mean(axis=0)
        expanded_pts = center + (pts - center) * 1.1
        expanded_pts = expanded_pts.astype(np.int32)

        cv2.fillPoly(mask, [expanded_pts.reshape((-1, 1, 2))], color=255)

    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    mask_pil = Image.fromarray(mask)

    if LAMA_AVAILABLE and lama_model is not None:
        try:
            result_pil = lama_model(img_pil, mask_pil)
            inpainted_img = cv2.cvtColor(np.array(result_pil), cv2.COLOR_RGB2BGR)
            print("   âœ… AI ä¿®å¤å®Œæˆï¼Œåº•çº¹å·²é‡å»º")
            return inpainted_img
        except Exception as e:
            print(f"   âŒ AI ä¿®å¤å¤±è´¥ï¼Œå›é€€åˆ° OpenCV ç®—æ³•: {e}")
            return cv2.inpaint(img, mask, 3, cv2.INPAINT_NS)
    else:
        return cv2.inpaint(img, mask, 3, cv2.INPAINT_NS)


# -----------------------------
# è‡ªåŠ¨æ¢è¡Œ
# -----------------------------
def should_wrap_text(item, text, bbox_width, draw, font):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨æ¢è¡Œ"""
    field = item.get("field", "").lower()

    if "address" in field:
        return True

    if "issued" in field:
        return True

    words = text.split(" ")
    if len(words) <= 3:
        bbox = draw.textbbox((0, 0), text, font=font)
        width = bbox[2] - bbox[0]

        if width <= bbox_width * 1.2:
            return False

    bbox = draw.textbbox((0, 0), text, font=font)
    width = bbox[2] - bbox[0]

    return width > bbox_width


def wrap_text(text, font, max_width, draw):
    """æŒ‰å•è¯è‡ªåŠ¨æ¢è¡Œï¼ˆè‹±æ–‡æœ€ä½³æ•ˆæœï¼‰"""
    words = text.split(" ")
    lines = []
    current = ""

    for word in words:
        test_line = (current + " " + word).strip()

        bbox = draw.textbbox((0, 0), test_line, font=font)
        w = bbox[2] - bbox[0]

        if w <= max_width:
            current = test_line
        else:
            if current:
                lines.append(current)
            current = word

    if current:
        lines.append(current)

    return lines


# -----------------------------
# å›¾ç‰‡æ“¦é™¤ + å¤šè¡Œå¡«å……
# -----------------------------
def inpaint_and_fill(img_path: str, items: List[Dict], output_path: str = None, auto_wrap: bool = True) -> str:
    """
    æ™ºèƒ½æ“¦é™¤åŸæ–‡å­—åŒºåŸŸï¼Œå¡«å……ç¿»è¯‘åçš„æ–‡æœ¬ï¼ˆæ”¯æŒè‡ªåŠ¨æ¢è¡Œ + åº•éƒ¨å¯¹é½ï¼‰
    
    Args:
        auto_wrap: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ¢è¡Œã€‚æ­£é¢(front)ä¸ºTrueï¼ŒèƒŒé¢(back)ä¸ºFalseã€‚
    """
    img = cv2.imread(img_path)
    if img is None:
        print("âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡")
        return None

    img = smart_inpaint(img, items)

    print("âœï¸ å¡«å……ç¿»è¯‘æ–‡æœ¬ï¼ˆè‡ªåŠ¨æ¢è¡Œ + åº•éƒ¨å¯¹é½ï¼‰...")

    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    # å°è¯•åŠ è½½å­—ä½“ï¼ˆå…¼å®¹Windowså’ŒLinuxï¼‰
    font_en_path = None
    font_zh_path = None
    
    # Windowså­—ä½“è·¯å¾„
    windows_fonts = {
        "en": "C:/Windows/Fonts/arial.ttf",
        "zh": "C:/Windows/Fonts/simhei.ttf"
    }
    
    # Linuxå­—ä½“è·¯å¾„
    linux_fonts = {
        "en": [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf",
        ],
        "zh": [
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",
            "/usr/share/fonts/truetype/arphic/uming.ttc",
        ]
    }
    
    # macOSå­—ä½“è·¯å¾„
    mac_fonts = {
        "en": "/System/Library/Fonts/Helvetica.ttc",
        "zh": "/System/Library/Fonts/PingFang.ttc"
    }
    
    # å°è¯•åŠ è½½è‹±æ–‡å­—ä½“
    if os.path.exists(windows_fonts["en"]):
        font_en_path = windows_fonts["en"]
    else:
        for path in linux_fonts["en"]:
            if os.path.exists(path):
                font_en_path = path
                break
        if not font_en_path and os.path.exists(mac_fonts["en"]):
            font_en_path = mac_fonts["en"]
    
    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
    if os.path.exists(windows_fonts["zh"]):
        font_zh_path = windows_fonts["zh"]
    else:
        for path in linux_fonts["zh"]:
            if os.path.exists(path):
                font_zh_path = path
                break
        if not font_zh_path and os.path.exists(mac_fonts["zh"]):
            font_zh_path = mac_fonts["zh"]

    for item in items:
        box = item.get("box")
        text = item.get("text", "")
        original_text = item.get("original_text", "")

        if not box or len(box) < 4 or not text:
            continue

        x1, y1 = box[0]
        x2, y2 = box[1]
        x3, y3 = box[2]
        x4, y4 = box[3]

        box_width = x2 - x1
        box_height = y3 - y1

        is_english = all(ord(c) < 128 or c.isspace() for c in text)
        font_path = font_en_path if is_english else font_zh_path

        font_size = 24
        min_font_size = 12
        best_font = None

        while font_size >= min_font_size:
            try:
                if font_path and os.path.exists(font_path):
                    test_font = ImageFont.truetype(font_path, font_size)
                else:
                    test_font = ImageFont.load_default()
            except Exception as e:
                test_font = ImageFont.load_default()

            # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„Pillow
            try:
                bbox = draw.textbbox((0, 0), text, font=test_font)
                text_h = bbox[3] - bbox[1]
            except AttributeError:
                # æ—§ç‰ˆæœ¬ä½¿ç”¨textsize
                try:
                    bbox = draw.textsize(text, font=test_font)
                    text_h = bbox[1]
                except:
                    text_h = font_size * 1.2  # ä¼°ç®—å€¼

            if text_h <= box_height * 1.1:
                best_font = test_font
                break

            font_size -= 1

        if best_font is None:
            try:
                if font_path and os.path.exists(font_path):
                    best_font = ImageFont.truetype(font_path, min_font_size)
                else:
                    best_font = ImageFont.load_default()
            except:
                best_font = ImageFont.load_default()

        if is_english and auto_wrap:
            if should_wrap_text(item, text, box_width, draw, best_font):
                lines = wrap_text(text, best_font, box_width, draw)
            else:
                lines = [text]
        else:
            lines = [text]

        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„getbboxæ–¹æ³•
        try:
            line_height = best_font.getbbox("A")[3] - best_font.getbbox("A")[1] + 6
        except AttributeError:
            try:
                # æ—§ç‰ˆæœ¬ä½¿ç”¨getsize
                line_height = best_font.getsize("A")[1] + 6
            except:
                line_height = font_size + 6  # ä¼°ç®—å€¼

        total_text_height = len(lines) * line_height

        y_start = y3 - total_text_height
        if y_start < y1:
            y_start = y1

        for i, line in enumerate(lines):
            y_line = y_start + i * line_height
            try:
                draw.text((int(x1), int(y_line)), line, font=best_font, fill=(0, 0, 0))
            except AttributeError:
                # å¦‚æœgetmask2æ–¹æ³•ä¸å­˜åœ¨ï¼Œå°è¯•ä¸ä½¿ç”¨fontå‚æ•°
                try:
                    draw.text((int(x1), int(y_line)), line, fill=(0, 0, 0))
                except Exception as e:
                    print(f"âš ï¸ ç»˜åˆ¶æ–‡æœ¬å¤±è´¥: {line}, é”™è¯¯: {e}")
                    continue

    img_out = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

    if output_path is None:
        output_path = os.path.splitext(img_path)[0] + ".translated.jpg"

    cv2.imwrite(output_path, img_out)
    print(f"âœ… ç¿»è¯‘åçš„å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_path}")

    return output_path


# -----------------------------
# å¯è§†åŒ–å‡½æ•°
# -----------------------------
def draw_visualization(img_path: str, items: List[Dict], save_path: str = None) -> str:
    """ç”ŸæˆOCRç»“æœå¯è§†åŒ–å›¾ç‰‡"""
    img = cv2.imread(img_path)
    if img is None:
        print("âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚")
        return None

    for it in items:
        box = it.get("box")
        if not box or len(box) < 4:
            continue
        pts = np.array(box, np.int32)
        cv2.polylines(img, [pts], isClosed=True, color=(0, 255, 0), thickness=2)

    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    # å°è¯•åŠ è½½å­—ä½“ï¼ˆå…¼å®¹Windowså’ŒLinuxï¼‰
    font = None
    font_paths = [
        "C:/Windows/Fonts/simhei.ttf",  # Windows
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",  # Linuxå¸¸è§è·¯å¾„
        "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",  # Linux
        "/System/Library/Fonts/Helvetica.ttc",  # macOS
    ]
    
    for path in font_paths:
        try:
            if os.path.exists(path):
                font = ImageFont.truetype(path, 18)
                break
        except:
            continue
    
    # å¦‚æœæ‰€æœ‰å­—ä½“éƒ½åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
    if font is None:
        try:
            font = ImageFont.load_default()
        except:
            # å¦‚æœé»˜è®¤å­—ä½“ä¹Ÿå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„å­—ä½“
            font = ImageFont.load_default()
    
    for it in items:
        box = it.get("box")
        text = it.get("text", "")
        if not box or len(box) < 4:
            continue
        x, y = box[0]
        try:
            # ä½¿ç”¨å…¼å®¹çš„æ–‡æœ¬ç»˜åˆ¶æ–¹æ³•
            draw.text((x, y - 20), text, font=font, fill=(255, 0, 0))
        except AttributeError:
            # å¦‚æœgetmask2æ–¹æ³•ä¸å­˜åœ¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            try:
                # å°è¯•ä½¿ç”¨getmaskæ–¹æ³•ï¼ˆæ—§ç‰ˆæœ¬å…¼å®¹ï¼‰
                draw.text((x, y - 20), text, fill=(255, 0, 0))
            except Exception as e:
                print(f"âš ï¸ ç»˜åˆ¶æ–‡æœ¬å¤±è´¥: {text}, é”™è¯¯: {e}")
                continue

    img_out = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    if save_path is None:
        save_path = os.path.splitext(img_path)[0] + ".vis.jpg"
    cv2.imwrite(save_path, img_out)
    print(f"ğŸ“Š å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_path}")
    return save_path


# -----------------------------
# ä¸»å¤„ç†å‡½æ•°
# -----------------------------
def process_image(
    input_path: str,
    output_dir: str = None,
    from_lang: str = 'zh',
    to_lang: str = 'en',
    enable_correction: bool = True,
    enable_visualization: bool = True,
    card_side: str = 'front'
) -> Dict[str, Any]:
    """
    å®Œæ•´çš„å›¾ç‰‡å¤„ç†æµç¨‹
    
    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        from_lang: æºè¯­è¨€
        to_lang: ç›®æ ‡è¯­è¨€
        enable_correction: æ˜¯å¦å¯ç”¨é€è§†çŸ«æ­£
        enable_visualization: æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡
        card_side: è¯ä»¶é¢ï¼Œ'front'=æ­£é¢ï¼ˆè‡ªåŠ¨æ¢è¡Œï¼‰ï¼Œ'back'=èƒŒé¢ï¼ˆä¸æ¢è¡Œï¼‰
    
    Returns:
        åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
    """
    if output_dir is None:
        output_dir = settings.OUTPUT_DIR
    
    os.makedirs(output_dir, exist_ok=True)
    
    base_name = os.path.splitext(os.path.basename(input_path))[0]
    
    print("=" * 60)
    print(f"ğŸš€ å¼€å§‹å¤„ç†å›¾ç‰‡ | card_side={card_side} | auto_wrap={card_side != 'back'}")
    print("=" * 60)

    # æ­¥éª¤0: å›¾åƒé¢„å¤„ç†
    print("\nğŸ”¨ æ­¥éª¤0: å›¾åƒæ ‡å‡†åŒ–å¤„ç†...")
    img_path = preprocess_resize_image(input_path, target_width=settings.TARGET_IMAGE_WIDTH)

    # æ­¥éª¤0.5: é€è§†çŸ«æ­£ï¼ˆå¯é€‰ï¼‰
    if enable_correction:
        print("\nğŸ“ æ­¥éª¤0.5: é€è§†çŸ«æ­£...")
        img_path = auto_correct_perspective(img_path)

    # æ­¥éª¤1: OCRè¯†åˆ«
    print("\nğŸ“· æ­¥éª¤1: OCR è¯†åˆ«ä¸­...")
    try:
        result = ocr.predict(img_path)  # PaddleOCR 3.x
    except (AttributeError, NotImplementedError):
        result = ocr.ocr(img_path)  # PaddleOCR 2.x é™çº§å…¼å®¹

    # æ­¥éª¤2: æå–æ–‡æœ¬
    print("ğŸ“ æ­¥éª¤2: æå–æ–‡æœ¬...")
    items = extract_all_items(result)
    print(f"   æ£€æµ‹åˆ° {len(items)} ä¸ªæ–‡æœ¬å—")

    # æ­¥éª¤3: æ™ºèƒ½åˆ†å‰²
    print("\nğŸ”§ æ­¥éª¤3: æ™ºèƒ½åˆ†å‰²ï¼ˆä¿æŠ¤æ—¥æœŸå’Œåœ°å€ï¼‰...")
    items = split_merged_items(items)
    print(f"   åˆ†å‰²åå…± {len(items)} ä¸ªæ–‡æœ¬å—")

    # æ­¥éª¤4: æ™ºèƒ½åˆå¹¶åœ°å€è¡Œ
    print("\nğŸ”— æ­¥éª¤4: æ™ºèƒ½åˆå¹¶åœ°å€è¡Œï¼ˆå¤šé‡åˆ¤æ–­ï¼‰...")
    items = merge_address_lines(items)
    print(f"   åˆå¹¶åå…± {len(items)} ä¸ªæ–‡æœ¬å—")

    # ä¿å­˜åŸå§‹OCRç»“æœ
    out_json = os.path.join(output_dir, f"{base_name}_raw_ocr.json")
    with open(out_json, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=4)
    print(f"   åŸå§‹OCRç»“æœå·²ä¿å­˜: {out_json}")

    # æ­¥éª¤5: ç”Ÿæˆå¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    vis_path = None
    if enable_visualization:
        print("\nğŸ“Š æ­¥éª¤5: ç”Ÿæˆåˆ†å‰²å¯è§†åŒ–...")
        vis_path = draw_visualization(img_path, items, 
                                     save_path=os.path.join(output_dir, f"{base_name}_vis.jpg"))

    # æ­¥éª¤6: ç¿»è¯‘
    if card_side == 'back':
        print("\nğŸŒ æ­¥éª¤6: èº«ä»½è¯èƒŒé¢ä¸“ç”¨ç¿»è¯‘ï¼ˆå›ºå®šæ˜ å°„ + å˜é‡ç¿»è¯‘ï¼‰...")
        translated_items = translate_all_items_backside(items, from_lang=from_lang, to_lang=to_lang)
    else:
        print("\nğŸŒ æ­¥éª¤6: DeepSeek æ‰¹é‡ç¿»è¯‘ï¼ˆä¼˜åŒ–æ ¼å¼ï¼‰...")
        translated_items = translate_all_items(items, from_lang=from_lang, to_lang=to_lang)

    # ä»…èƒŒé¢ï¼šå¯¹ã€Œç­¾å‘æœºå…³ã€é¡¹æ‹‰å®½ boxï¼Œä½¿ "Issuing Authority" å•è¡Œ
    if card_side == 'back':
        for it in translated_items:
            if it.get("original_text") != "ç­¾å‘æœºå…³":
                continue
            box = it.get("box")
            if box and len(box) >= 4:
                it["box"] = _expand_box_right(box, BACKSIDE_ISSUING_AUTHORITY_BOX_EXTRA_WIDTH)
                print(f"   â†’ ç­¾å‘æœºå…³ box å³æ‰© {BACKSIDE_ISSUING_AUTHORITY_BOX_EXTRA_WIDTH}px")

    trans_json = os.path.join(output_dir, f"{base_name}_translated.json")
    with open(trans_json, "w", encoding="utf-8") as f:
        json.dump(translated_items, f, ensure_ascii=False, indent=4)
    print(f"\nâœ… ç¿»è¯‘ç»“æœå·²ä¿å­˜: {trans_json}")

    # æ­¥éª¤7: æ™ºèƒ½ä¿®å¤å¹¶å¡«å……ç¿»è¯‘
    print("\nğŸ¨ æ­¥éª¤7: æ™ºèƒ½ä¿®å¤å¹¶å¡«å……ç¿»è¯‘...")
    output_img = inpaint_and_fill(
        img_path, 
        translated_items,
        output_path=os.path.join(output_dir, f"{base_name}_translated.jpg")
    )

    print("\n" + "=" * 60)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("=" * 60)

    return {
        "input_path": input_path,
        "processed_image": img_path,
        "raw_ocr_json": out_json,
        "translated_json": trans_json,
        "visualization": vis_path,
        "final_output": output_img,
        "items_count": len(items)
    }

